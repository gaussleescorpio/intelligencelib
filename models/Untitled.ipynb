{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline \n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from matplotlib import pylab as plt\n",
    "import numpy as np\n",
    "from statsmodels.tsa import stattools as stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"data/MiscStat.xlsx-20160201.xls\")\n",
    "data = data.append(pd.read_excel(\"data/MiscStat.xlsx-20160202.xls\"))\n",
    "data = data.append(pd.read_excel(\"data/MiscStat.xlsx-20160203.xls\"))\n",
    "data = data.append(pd.read_excel(\"data/MiscStat.xlsx-20160204.xls\"))\n",
    "data = data.append(pd.read_excel(\"data/MiscStat.xlsx-20160205.xls\"))\n",
    "data = data.append(pd.read_excel(\"data/MiscStat.xlsx-20160206.xls\"))\n",
    "data = data.append(pd.read_excel(\"data/MiscStat.xlsx-20160207.xls\"))\n",
    "data = data.append(pd.read_excel(\"data/MiscStat.xlsx-20160208.xls\"))\n",
    "data = data.append(pd.read_excel(\"data/MiscStat.xlsx-20160209.xls\"))\n",
    "data = data.append(pd.read_excel(\"data/MiscStat.xlsx-20160210.xls\"))\n",
    "data = data.append(pd.read_excel(\"data/MiscStat.xlsx-20160211.xls\"))\n",
    "data = data.append(pd.read_excel(\"data/MiscStat.xlsx-20160212.xls\"))\n",
    "data = data.append(pd.read_excel(\"data/MiscStat.xlsx-20160213.xls\"))\n",
    "data = data.append(pd.read_excel(\"data/MiscStat.xlsx-20160214.xls\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "google_data = data[data[\"PartnerDomain\"] == \"google\"]\n",
    "google_data.head(1000)\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "supersave_data = google_data[google_data[\"Site\"]==\"supersaver_se\"]\n",
    "supersave_data.set_index(\"OrderDateTime\")\n",
    "plt.grid(True)\n",
    "plt.plot_date(pd.to_datetime(supersave_data.OrderDateTime), supersave_data.MrkCost,\"o-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e+00  -2.56123157e-01  -7.66073235e-02  -1.66964859e-02\n",
      "  -3.53430416e-03  -7.42759909e-04  -2.89270154e-04  -2.34805053e-04\n",
      "  -6.08997689e-02   2.69974523e-02   1.89198293e-02   1.67628316e-02\n",
      "  -1.31192008e-04  -1.57916665e-03  -1.37724123e-03  -1.25483371e-03\n",
      "  -2.79409542e-03   4.27071723e-03   4.52724895e-04  -1.71443068e-04\n",
      "  -1.93871623e-03  -9.50326356e-04  -5.53324125e-03   2.37283350e-03\n",
      "   1.53735081e-03   9.96626923e-04  -1.05918707e-04  -1.88112357e-02\n",
      "   7.88459963e-03   8.23128293e-03  -1.52650477e-03   1.95912333e-03\n",
      "   5.36389893e-04   3.58723043e-02  -1.62939184e-01  -9.53923322e-02\n",
      "  -2.77965188e-02  -7.09099420e-03  -7.13252076e-02   2.86397079e-02\n",
      "   2.17056605e-02]\n"
     ]
    }
   ],
   "source": [
    "from statsmodels import tsa\n",
    "plt.bar(range(len(stat.acf(supersave_data.MrkCost))),stat.acf(supersave_data.MrkCost), width=0.01)\n",
    "diff = supersave_data.MrkCost.diff()\n",
    "diff = diff.fillna(0.0)\n",
    "diff_acf =  stat.pacf(diff)\n",
    "plt.figure()\n",
    "plt.ylim(-0.5,0.2)\n",
    "print diff_acf\n",
    "plt.bar(range(len(diff_acf)),stat.pacf(diff,method=\"ols\"), width=0.01)\n",
    "plt.axhline(y = -0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501\n",
      "669\n"
     ]
    }
   ],
   "source": [
    "training_data = supersave_data.MrkCost.values[0:500]\n",
    "arima_model = tsa.arima_model.ARIMA(training_data, (2,0,1))\n",
    "fit_model = arima_model.fit(trend='c')\n",
    "\n",
    "pred = arima_model.predict(params=fit_model.params,start=0,end=500,dynamic=False)\n",
    "print pred.size\n",
    "print supersave_data.OrderDateTime[0:-1].size\n",
    "plt.plot_date(pd.to_datetime(supersave_data.OrderDateTime[0:500]), supersave_data.MrkCost[0:500],\"-\")\n",
    "plt.figure()\n",
    "#plt.plot_date(pd.to_datetime(supersave_data.OrderDateTime[:]), pred, \"r-\")\n",
    "plt.plot(range( len(pred) ), pred, \"r-\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import scipy\n",
    "# import numpy as np\n",
    "# from scipy import stats\n",
    "# from matplotlib import pylab as plt\n",
    "# import category_encoders as ce\n",
    "# import operator\n",
    "\n",
    "# # silience the chained-assignment warning\n",
    "# pd.set_option('chained_assignment',None)\n",
    "\n",
    "# class BinEncoder():\n",
    "#     def __init__(self, max_bins=5):\n",
    "#         \"\"\"\n",
    "#         :param data: input data that must be a pandas dataframe\n",
    "#         :param num_bins: intended num of bins\n",
    "#         :return:\n",
    "#         \"\"\"\n",
    "#         self.max_bins = max_bins\n",
    "#         self.actual_bins = 0\n",
    "#         self.b = np.array([])\n",
    "#         self.freq = []\n",
    "#         self.fit_flag = False\n",
    "#         self.map_tmp = {}\n",
    "#         self.bin_id_record={}\n",
    "\n",
    "#     def occurence_count(self, data=pd.Series()):\n",
    "#         \"\"\"\n",
    "#         calculate the frequency for each unique id.\n",
    "#         :return: the occurrence for each unique id\n",
    "#         \"\"\"\n",
    "#         occ = dict({})\n",
    "#         for val in data.values:\n",
    "#             occ[val] = 0\n",
    "#         for val in data.values:\n",
    "#             occ[val] += 1\n",
    "#         return occ\n",
    "\n",
    "#     def ordering_id_map(self, data=pd.Series()):\n",
    "#         \"\"\"\n",
    "#         Map the original random ID to the ordering ID based on frequency\n",
    "#         :return: mapped data marked by ordering numbers\n",
    "#         \"\"\"\n",
    "#         if not self.fit_flag:\n",
    "#             tmp_occurrence = self.occurence_count(data)\n",
    "#             tmp_sorted_bin = sorted(tmp_occurrence.items(), key=operator.itemgetter(1), reverse=True)\n",
    "#             tmp_sorted_bin = np.asarray( tmp_sorted_bin )\n",
    "#             for o,origid in enumerate(tmp_sorted_bin[:,0]):\n",
    "#                 self.map_tmp[origid] = o\n",
    "#             print \"finished mapping construction......\"\n",
    "#         length = len(self.map_tmp)\n",
    "#         i= 0\n",
    "#         for key,u in zip(self.map_tmp.keys(), self.map_tmp.values()):\n",
    "#             i+= 1.0\n",
    "#             if i%100 == 0:\n",
    "#                 print \"finished %.5f percentage\" %( float(i/length) *100 )\n",
    "\n",
    "#             row_index = data == key\n",
    "#             data.loc[row_index] = u\n",
    "\n",
    "#         print type(data), type(self.map_tmp)\n",
    "#         diff = set( data.values ) - set(self.map_tmp.values() )\n",
    "#         print diff\n",
    "#         if not diff:\n",
    "#             pass\n",
    "#         else:\n",
    "#             print \"warning: there are new alien data sent in, please fit with the new data...\"\n",
    "#             for p in list(diff):\n",
    "#                 row_index = data==p\n",
    "#                 data.loc[row_index] = np.nan\n",
    "#         return data\n",
    "\n",
    "#     def log_n(self, data, n):\n",
    "#         \"\"\"\n",
    "#         log transformation of the input data\n",
    "#         :param data: input data\n",
    "#         :param n: n times log taken\n",
    "#         :return: transformed data\n",
    "#         \"\"\"\n",
    "#         data = np.log(data)\n",
    "#         # print \"%.2f th data result is %s\" %(n, str(data))\n",
    "#         if n <= 1.00:\n",
    "#             # print \"returned... %s\" %str(data)\n",
    "#             return data\n",
    "#         else:\n",
    "#             return self.log_n(data + 1, n-1)\n",
    "\n",
    "#     def bin_id_map(self, p, transformed_id):\n",
    "#         \"\"\"\n",
    "#         Map the ordering ID to bin ID\n",
    "#         :param p: an array which contains value scope for each bin\n",
    "#         :param transformed_id: transformed ordering ID\n",
    "#         :return:  data marked by bin ID\n",
    "#         \"\"\"\n",
    "#         assert  isinstance(transformed_id, pd.Series), \"check out your input type...\"\n",
    "#         if not self.fit_flag:\n",
    "#             a = 0\n",
    "#             b = 0\n",
    "#             id_bin = 0\n",
    "#             for i in range(len(p)-1):\n",
    "#                 a = b\n",
    "#                 b = p[i+1]\n",
    "#                 jd = transformed_id.between(a,b)\n",
    "#                 if (jd==True).any():\n",
    "#                     id_bin += 1\n",
    "#                     transformed_id[jd] = id_bin\n",
    "#                     self.bin_id_record[id_bin] = [a,b]\n",
    "#             self.actual_bins = id_bin\n",
    "#         else:\n",
    "#             for key, u in zip(self.bin_id_record.keys(),self.bin_id_record.values()):\n",
    "#                 transformed_id[transformed_id.between(u[0],u[1])] = key\n",
    "#         return transformed_id\n",
    "\n",
    "\n",
    "#     def fit(self, data=pd.Series(),show_diag=True):\n",
    "#         \"\"\"\n",
    "#         Automatic binning process, the result is put in the self.data\n",
    "#         :param show_diag: True for showing the binning histogram\n",
    "#         :return:\n",
    "#         \"\"\"\n",
    "#         data = self.ordering_id_map(data)\n",
    "#         # tmp_occurrence = self.occurence_count(data)\n",
    "#         # tmp_sorted_bin = sorted(tmp_occurrence.items(), key=operator.itemgetter(1), reverse=True)\n",
    "#         # tmp_sorted_bin = np.asarray( tmp_sorted_bin )\n",
    "#         # use matplotlib even-spaced binning\n",
    "#         trans_id = self.log_n(data + 1, 2)\n",
    "#         self.freq,self.b,p = plt.hist(trans_id , bins=self.max_bins)\n",
    "#         data = self.bin_id_map(self.b, trans_id)\n",
    "#         self.fit_flag = True\n",
    "#         if show_diag:\n",
    "#             plt.show()\n",
    "\n",
    "#     def transform(self, data = pd.Series()):\n",
    "#         \"\"\"\n",
    "#         :param data: target data\n",
    "#         :return: transformed data with previous fit\n",
    "#         \"\"\"\n",
    "#         if not self.fit_flag:\n",
    "#             raise Exception(\"You have not fitted your model yet...\")\n",
    "#         data = self.ordering_id_map(data)\n",
    "#         trans_id = self.log_n(data+1, 2)\n",
    "#         tran_data = self.bin_id_map(self.b, trans_id)\n",
    "#         print tran_data\n",
    "#         tran_data.fillna(self.actual_bins + 1)\n",
    "#         return tran_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # path where you put the testing data\n",
    "#     path = \"/Users/gausslee/Documents/programming/etravelipython/ibemingdata/newsql_data20132014n.csv\"\n",
    "#     data = pd.read_csv(path)\n",
    "#     raw_data = list(data)\n",
    "#     print \"data loaded...................\"\n",
    "#     selection_cols = [ 'OrderDay','SiteID', 'SiteCountryID',\n",
    "#      'FirstAirSystem',\n",
    "#      'TravelDays', 'DaysAhead' , 'IsInterCont', 'JouneyType',\n",
    "#      'NumBounds', 'NumSegs', 'Bound2StartSeg1Bs', 'NumofAd',\n",
    "#      'NumofCh', 'Numofinf', 'ServDays', 'Net', 'TaxExVat', 'Vat',\n",
    "#      'MarkupSeg', 'BookType','OriginAirportID', 'OriginCityID','OriginCountryID', 'DestCityID', 'DestCoutID','MarketCostSek']\n",
    "#     training_data = data[selection_cols]\n",
    "#     binning =  BinEncoder(max_bins = 20)\n",
    "#     print \"start to bin....\"\n",
    "#     binning.fit(training_data[\"SiteID\"],  False)\n",
    "#     data = binning.transform(training_data[\"SiteID\"])\n",
    "#     print data.to_csv(\"data.csv\")\n",
    "#     alien_data = pd.Series([-9999, 39, -19])\n",
    "#     alien_data = binning.transform(alien_data)\n",
    "#     print alien_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
